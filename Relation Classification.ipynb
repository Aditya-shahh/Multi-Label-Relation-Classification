{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDW-X3yKeQML",
    "outputId": "2be3b273-ac1e-45d6-eeb0-8c87b518441e"
   },
   "outputs": [],
   "source": [
    "cd /content/drive/MyDrive/NLP HW - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DIs_PXtKUlKM"
   },
   "outputs": [],
   "source": [
    "# Read data (.sent files)\n",
    "def read_data(data_file):\n",
    "  data = []\n",
    "\n",
    "  with open(data_file) as f:\n",
    "    contents = f.readlines()\n",
    "    for line in contents:\n",
    "      data.append(line)\n",
    "\n",
    "  return data \n",
    "\n",
    "\n",
    "# Read pointer file\n",
    "def read_pointer_file(pointer_file):\n",
    "  pointers = []\n",
    "  with open(pointer_file) as f:\n",
    "    contents = f.readlines()\n",
    "    for line in contents:\n",
    "      lines = line.split(\"|\")\n",
    "      pointers.append(lines)\n",
    "\n",
    "  return pointers\n",
    "\n",
    "\n",
    "#Read tuple file\n",
    "def read_tuple_file(tuple_file):\n",
    "  tuples = []\n",
    "  with open(tuple_file) as f:\n",
    "    contents = f.readlines()\n",
    "    for line in contents:\n",
    "      lines = line.split(\"|\")\n",
    "      tuples.append(lines)\n",
    "\n",
    "  return tuples\n",
    "\n",
    "# Map relations to ids\n",
    "def get_label_mapping(label_file):\n",
    "  label2idx = {}\n",
    "\n",
    "  with open(label_file) as f:\n",
    "    contents = f.readlines()\n",
    "    for label in contents:\n",
    "      label = label.strip()\n",
    "      label2idx[label] = len(label2idx)\n",
    "  \n",
    "  # add other class\n",
    "  label2idx['other'] = 29\n",
    "\n",
    "  return label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PiEbpPQCvor-"
   },
   "outputs": [],
   "source": [
    "train_data = read_data('train.sent')\n",
    "val_data = read_data('dev.sent')\n",
    "test_data = read_data('test.sent')\n",
    "\n",
    "train_pointers = read_pointer_file('train.pointer')\n",
    "val_pointers = read_pointer_file('dev.pointer')\n",
    "test_pointers = read_pointer_file('test.pointer')\n",
    "\n",
    "train_tuples = read_tuple_file('train.tup')\n",
    "val_tuples = read_tuple_file('dev.tup')\n",
    "test_tuples = read_tuple_file('test.tup')\n",
    "\n",
    "labels_dir = 'relations.txt'\n",
    "label2idx = get_label_mapping(labels_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/location/administrative_division/country': 0,\n",
       " '/location/country/capital': 1,\n",
       " '/location/country/administrative_divisions': 2,\n",
       " '/location/neighborhood/neighborhood_of': 3,\n",
       " '/location/location/contains': 4,\n",
       " '/people/person/nationality': 5,\n",
       " '/people/person/place_lived': 6,\n",
       " '/people/deceased_person/place_of_death': 7,\n",
       " '/business/person/company': 8,\n",
       " '/location/us_state/capital': 9,\n",
       " '/people/person/place_of_birth': 10,\n",
       " '/people/person/children': 11,\n",
       " '/business/company/founders': 12,\n",
       " '/business/company/place_founded': 13,\n",
       " '/sports/sports_team/location': 14,\n",
       " '/people/person/ethnicity': 15,\n",
       " '/people/ethnicity/geographic_distribution': 16,\n",
       " '/people/person/religion': 17,\n",
       " '/business/company/major_shareholders': 18,\n",
       " '/location/province/capital': 19,\n",
       " '/location/br_state/capital': 20,\n",
       " '/business/company/advisors': 21,\n",
       " '/film/film_location/featured_in_films': 22,\n",
       " '/film/film/featured_film_locations': 23,\n",
       " '/location/us_county/county_seat': 24,\n",
       " '/time/event/locations': 25,\n",
       " '/people/deceased_person/place_of_burial': 26,\n",
       " '/people/place_of_interment/interred_here': 27,\n",
       " '/business/company_advisor/companies_advised': 28,\n",
       " 'other': 29}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relation to class mapping\n",
    "label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "mFXncN7HVS9J"
   },
   "outputs": [],
   "source": [
    "# returns a list of other entity pairs\n",
    "def get_other_entity_pairs(relations, entites): \n",
    "  unique_pairs = set()\n",
    "\n",
    "  for i in entites:\n",
    "    for j in entites:\n",
    "      if i!=j:\n",
    "        if (i, j) not in relations:\n",
    "          unique_pairs.add( (i, j))\n",
    "\n",
    "\n",
    "  return list(unique_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "nutHEt-Dqg-T"
   },
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "\n",
    "#Input - sentence, pointer, tuple files\n",
    "#Output - sentence with special tokens inserted( <s1>, <e1>, <s2>, <e2>) and one hot labels for all given entity pairs\n",
    "\n",
    "def preprocess_data(data, pointers_data, tuples_data, evaluation = False):\n",
    "  sentences = []\n",
    "  labels = []\n",
    "\n",
    "  for i in range(len(data)):\n",
    "    pointer = pointers_data[i]\n",
    "\n",
    "    tuples = tuples_data[i]\n",
    "\n",
    "    relations = set()\n",
    "    entites = set()\n",
    "    maps = {}\n",
    "\n",
    "    # for all the given entites\n",
    "    for item, tuple  in zip(pointer, tuples):\n",
    "        \n",
    "      line = data[i]\n",
    "      line = line.strip().split(\" \")\n",
    "      \n",
    "      # add entity tuple to relation\n",
    "      tuple = tuple.strip().split(\";\")\n",
    "      relations.add(( tuple[0].strip(), tuple[1].strip() ))\n",
    "\n",
    "      # store the tuples in entity\n",
    "      entites.add(tuple[0].strip())\n",
    "      entites.add(tuple[1].strip())\n",
    "      \n",
    "      item = item.strip().split(\" \")\n",
    "        \n",
    "      s_1 = int(item[0])\n",
    "      e_1 = int(item[1])\n",
    "      s_2 = int(item[2])\n",
    "      e_2 = int(item[3])\n",
    "        \n",
    "      maps[tuple[0].strip()] = (s_1, e_1)\n",
    "      maps[tuple[1].strip()] = (s_2, e_2)\n",
    "\n",
    "\n",
    "      #get label for the relation\n",
    "      label = label2idx[item[4]]\n",
    "\n",
    "      line.insert(s_1, \"<s1>\")\n",
    "      line.insert(e_1+2, \"<e1>\")\n",
    "    \n",
    "      if s_2 > e_1:\n",
    "            line.insert(s_2 +2, \"<s2>\")\n",
    "            line.insert(e_2 + 4, \"<e2>\")\n",
    "      else:\n",
    "            line.insert(s_2, \"<s2>\")\n",
    "            line.insert(e_2 +2, \"<e2>\")\n",
    "        \n",
    "    \n",
    "      line =  \" \".join(line)\n",
    "\n",
    "      if line in sentences:\n",
    "        index = sentences.index(line)\n",
    "        current_y = labels[index]\n",
    "        current_y[label] = 1\n",
    "        labels[index] = current_y\n",
    "\n",
    "      else:\n",
    "        y = [0]*29\n",
    "        y[label] = 1\n",
    "        sentences.append(line)\n",
    "        labels.append(y)\n",
    "        \n",
    "    if not evaluation:\n",
    "\n",
    "        #get other pairs\n",
    "        other_pairs = get_other_entity_pairs(relations, entites)\n",
    "\n",
    "        if other_pairs != []:\n",
    "          for other_pair in other_pairs:\n",
    "              line = data[i]\n",
    "              line = line.strip().split(\" \")\n",
    "\n",
    "              entity_1 = other_pair[0].strip()\n",
    "              entity_2 = other_pair[1].strip()\n",
    "\n",
    "              s_1, e_1 = maps[entity_1]\n",
    "              s_2, e_2 = maps[entity_2]\n",
    "\n",
    "              line.insert(int(s_1), \"<s1>\")\n",
    "              line.insert(int(e_1)+2, \"<e1>\")\n",
    "\n",
    "              if s_2 > e_1:\n",
    "                s_2_pos = s_2 + 2\n",
    "                e_2_pos = e_2 + 4\n",
    "                line.insert(s_2_pos, \"<s2>\")\n",
    "                line.insert(e_2_pos, \"<e2>\")\n",
    "              else:\n",
    "                line.insert(int(s_2), \"<s2>\")\n",
    "                line.insert(int(e_2) +2, \"<e2>\")\n",
    "\n",
    "              line =  \" \".join(line)\n",
    "\n",
    "              #other label -- array of all zeros \n",
    "              y = [0]*29\n",
    "\n",
    "              if line not in sentences:\n",
    "                sentences.append(line)\n",
    "                labels.append(y)\n",
    "\n",
    "\n",
    "\n",
    "  return sentences, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ZpvP5h1Os9dd"
   },
   "outputs": [],
   "source": [
    "train_sentences, train_labels = preprocess_data(train_data, train_pointers, train_tuples)\n",
    "\n",
    "val_sentences, val_labels = preprocess_data(val_data, val_pointers, val_tuples, evaluation = True)\n",
    "\n",
    "test_sentences, test_labels = preprocess_data(test_data, test_pointers, test_tuples, evaluation = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkdcRUiYSxIT"
   },
   "source": [
    "### Save data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "0c2T2ssFBwtk"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('train.pkl', 'wb') as f:\n",
    "  pickle.dump( (train_sentences, train_labels),  f)\n",
    "\n",
    "with open('val.pkl', 'wb') as f:\n",
    "  pickle.dump((val_sentences, val_labels), f)\n",
    "\n",
    "with open('test.pkl', 'wb') as f:\n",
    "  pickle.dump( (test_sentences, test_labels), f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5aX0qeKXsv-"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "OHsh8TdDXZ9X"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUfr2lGKXu_k",
    "outputId": "a48525ba-5036-4cef-84ea-c709bd9b5bc8"
   },
   "outputs": [],
   "source": [
    "# cd /content/drive/MyDrive/NLP HW - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfpU_q01ncyx",
    "outputId": "2e12f548-4894-41a6-b0bd-3fab2c4984e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n",
      "8\n",
      "GPU Allocated\n"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled   = True\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "print('GPU Allocated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocrFjb8PSuVj"
   },
   "source": [
    "### Load saved data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "iiRfR4EDD3iO"
   },
   "outputs": [],
   "source": [
    "# load train, val, test files\n",
    "\n",
    "with open('train.pkl', 'rb') as f:\n",
    "  train_sentences, train_labels = pickle.load(f)\n",
    "\n",
    "with open('val.pkl', 'rb') as f:\n",
    "  val_sentences, val_labels = pickle.load(f)\n",
    "\n",
    "with open('test.pkl', 'rb') as f:\n",
    "  test_sentences, test_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvrhw_1RkCy5"
   },
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "IoV3pNAXdfE8"
   },
   "outputs": [],
   "source": [
    "## Specify the Hyper parameters \n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 4\n",
    "LEARNING_RATE = 3e-5\n",
    "CLIP = 2\n",
    "\n",
    "\n",
    "hidden_size = 64\n",
    "vocab_size = 4\n",
    "embed_dim = 256\n",
    "num_class =  29\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkiM6FvUWxN4"
   },
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "zItCIa_lQHmI"
   },
   "outputs": [],
   "source": [
    "# Import transformer tokenizer, model and optimizer\n",
    "\n",
    "from transformers import ElectraTokenizer, ElectraModel, AdamW\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n",
    "\n",
    "# add special tokens\n",
    "special_tokens_dict = {'additional_special_tokens': ['<s1>','<e1>','<s2>','<e2>']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "MzQTvKNtWz0x"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    This is our custom dataset class which will load the text and their corresponding labels into Pytorch tensors\n",
    "    \"\"\"\n",
    "    def __init__(self, labels, text):\n",
    "        self.labels = labels\n",
    "        self.text = text\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "        text = self.text[idx]\n",
    "\n",
    "        #Roberta Tokenizer to tokenize the text\n",
    "        indexed_tokens = tokenizer.encode_plus(text, \n",
    "                                               add_special_tokens=True,   # Adds [CLS] and [SEP] token to every input text\n",
    "                                               max_length=128, \n",
    "                                               truncation=True, \n",
    "                                               return_tensors='pt',\n",
    "                                               padding=\"max_length\")['input_ids']\n",
    "        \n",
    "\n",
    "        tokens = tokenizer.encode(text)\n",
    "        \n",
    "        \n",
    "        s_1, e_1, s_2, e_2 = tokens.index(30522), tokens.index(30523), tokens.index(30524), tokens.index(30525)\n",
    "        \n",
    "\n",
    "        \n",
    "        entity_mask = [0] * 128   # create entity mask \n",
    "        \n",
    "        for i in range(len(entity_mask)):\n",
    "            if i>=s_1 and i <=e_1:\n",
    "                entity_mask[i] =1\n",
    "                \n",
    "            if i>=s_2 and i <=e_2:\n",
    "                entity_mask[i] = 2\n",
    "                \n",
    "            if i>=len(tokens):\n",
    "                entity_mask[i] = 3\n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "        try:\n",
    "            sample[\"label\"] = torch.tensor(self.labels[idx])\n",
    "            sample[\"token\"] = indexed_tokens\n",
    "            sample[\"mask\"] = torch.tensor(entity_mask)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "bE3Jty9IW_q8"
   },
   "outputs": [],
   "source": [
    "# Create train, test and val datasets\n",
    "train_data_object = Dataset(\n",
    "    labels = train_labels,\n",
    "    text = train_sentences,\n",
    ")\n",
    "\n",
    "test_data_object = Dataset(\n",
    "    labels = test_labels,\n",
    "    text = test_sentences,\n",
    ")\n",
    "\n",
    "val_data_object = Dataset(\n",
    "    labels = val_labels,\n",
    "    text = val_sentences,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wSFoD2EMaR-Z",
    "outputId": "c19042f5-31fc-4c3f-9155-5ef229b96eb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30522, 30523, 30524, 30525]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.additional_special_tokens_ids     # token ids of inserted tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "axEEDg49dYp-"
   },
   "outputs": [],
   "source": [
    "\n",
    "## We call the dataloader class\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data_object,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    " )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data_object,\n",
    "    batch_size=BATCH_SIZE//2,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    " )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_data_object,\n",
    "    batch_size=BATCH_SIZE//2,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    " )\n",
    "\n",
    "dataloaders = {'Train': train_loader, 'Test': test_loader, 'Val': val_loader}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aoPmJUtdqqs"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fie_uzNveWe6",
    "outputId": "43131ab5-0eb1-453e-82fa-6fd1768a4412"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30526, 128)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electra = ElectraModel.from_pretrained(\"google/electra-small-discriminator\")\n",
    "electra.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoded Entity representation\n",
    "\n",
    "class EntityPair(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "      super(EntityPair, self).__init__()\n",
    "\n",
    "      self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = 3)\n",
    "      self.embedding.weight.requires_grad = True\n",
    "\n",
    " \n",
    "      self.fc1 = nn.Linear(embed_dim, embed_dim//2)\n",
    "\n",
    "        \n",
    "      self.adaptive = nn.AdaptiveMaxPool2d((1, embed_dim))\n",
    "\n",
    "      self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, mask):\n",
    "        \n",
    "      embed_output = self.embedding(mask)             #out shape = [batch, seq_len, embed_dim] \n",
    "    \n",
    "      out = self.adaptive(embed_output).squeeze()     #out shape = [batch, embed_dim]\n",
    "        \n",
    "      out = self.dropout(F.relu(self.fc1(out)))       #out shape = [batch, embed_dim/2]\n",
    "      \n",
    "      return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationClassification(nn.Module):\n",
    "\n",
    "    def __init__(self, electra, hidden_size, vocab_size, embed_dim, num_class):\n",
    "        \n",
    "      super(RelationClassification, self).__init__()\n",
    "\n",
    "      self.electra = electra\n",
    "        \n",
    "      self.entity_encoder = EntityPair(vocab_size, embed_dim)\n",
    "    \n",
    "      self.adaptive = nn.AdaptiveMaxPool2d((1, embed_dim))\n",
    "\n",
    "\n",
    " \n",
    "      self.fc1 = nn.Linear(embed_dim + embed_dim//2, hidden_size)\n",
    "      self.fc2 = nn.Linear(hidden_size, num_class)\n",
    "\n",
    "      self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input, mask):\n",
    "\n",
    "      electra_output = self.electra(input).last_hidden_state   #out shape = [batch, seq_len, 256]\n",
    "    \n",
    "      sentence_encoded = self.adaptive(electra_output).squeeze()  #out shape = [batch, embed_dim ] \n",
    "    \n",
    "    \n",
    "      entity_encoded = self.entity_encoder(mask)     #out shape =   [batch, embed_dim/2 ]\n",
    "        \n",
    "        \n",
    "      concat = torch.cat( (sentence_encoded, entity_encoded), 1)    #out_shape = [batch, embed_dim + embed_dim/2]\n",
    "\n",
    "        \n",
    "      concat_output = self.dropout(F.relu(self.fc1(concat)))      # out shape = batch, hidden_size\n",
    "    \n",
    "      final_output = F.sigmoid((self.fc2(concat_output)))        #out shape = batch, num_class\n",
    "      \n",
    "    \n",
    "      return final_output\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CdeOpRr8dn8y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "7pwNViJldpwt"
   },
   "outputs": [],
   "source": [
    "model = RelationClassification(electra, hidden_size, vocab_size, embed_dim, num_class)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "x1S9mpf6gYX9"
   },
   "outputs": [],
   "source": [
    "#optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = LEARNING_RATE, eps=1e-8 )\n",
    "#Loss function\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju0mAy39vaoh"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'electra_embed.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.0000e-05.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWRcbB9zgauk",
    "outputId": "3cbe6faa-052c-450a-bbbc-629a7073ba46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9148/9148 [10:06<00:00, 15.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "Micro F1: 0.56899173, Precision: 0.58695945, Recall : 0.55209138, Loss: 0.05155015.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [00:16<00:00, 62.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "Micro F1: 0.92561305, Precision: 0.95254769, Recall : 0.90015974, Loss: 0.01758949.\n",
      "\n",
      "Model Saved!\n",
      "Adjusting learning rate of group 0 to 3.0000e-05.\n",
      "--------------------------------------------------\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9148/9148 [09:48<00:00, 15.55batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "Micro F1: 0.89111778, Precision: 0.91863983, Recall : 0.86519685, Loss: 0.01220640.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [00:15<00:00, 64.29batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "Micro F1: 0.93733994, Precision: 0.93505166, Recall : 0.93963943, Loss: 0.01264862.\n",
      "\n",
      "Model Saved!\n",
      "Adjusting learning rate of group 0 to 1.5000e-05.\n",
      "--------------------------------------------------\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9148/9148 [09:51<00:00, 15.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "Micro F1: 0.92246886, Precision: 0.94128346, Recall : 0.90439165, Loss: 0.00810605.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [00:16<00:00, 62.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "Micro F1: 0.94745259, Precision: 0.94853614, Recall : 0.94637152, Loss: 0.01072068.\n",
      "\n",
      "Model Saved!\n",
      "Adjusting learning rate of group 0 to 1.5000e-05.\n",
      "--------------------------------------------------\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9148/9148 [09:48<00:00, 15.53batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "Micro F1: 0.93492243, Precision: 0.94995295, Recall : 0.92036015, Loss: 0.00671957.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1017/1017 [00:17<00:00, 56.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val:\n",
      "Micro F1: 0.95460782, Precision: 0.95657654, Recall : 0.95264719, Loss: 0.00982205.\n",
      "\n",
      "Model Saved!\n",
      "Adjusting learning rate of group 0 to 7.5000e-06.\n"
     ]
    }
   ],
   "source": [
    "best_valid_f1 = 0\n",
    "\n",
    "for epoch in range(0, EPOCHS):\n",
    "  \n",
    "\n",
    "    print('-'*50)\n",
    "    print('Epoch {}/{}'.format(epoch+1, EPOCHS))\n",
    "\n",
    "    for phase in ['Train', 'Val']:\n",
    "\n",
    "        batch_loss = 0.0000   #epoch loss\n",
    "\n",
    "        #accuracy = 0.0   #epoch accuracy\n",
    "\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        if phase == 'Train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        \n",
    "        with tqdm(dataloaders[phase], unit=\"batch\") as tepoch:\n",
    "\n",
    "          for batch in tepoch:\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            text = batch[\"token\"].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "\n",
    "            labels = labels.to(torch.float32)\n",
    "            text = text.squeeze()\n",
    "\n",
    "            output = model(text, mask)\n",
    "            \n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            if phase == 'Train':\n",
    "\n",
    "                #zero gradients\n",
    "                optimizer.zero_grad() \n",
    "\n",
    "                # Backward pass  (calculates the gradients)\n",
    "                loss.backward()   \n",
    "\n",
    "                # gradient clipping\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), CLIP)    \n",
    "\n",
    "                optimizer.step()             # Updates the weights    \n",
    "\n",
    "            labels_numpy = labels.detach().cpu().numpy()\n",
    "            hard_preds = torch.round(output).detach().cpu().numpy()\n",
    "            \n",
    "            y_pred.extend(hard_preds.tolist())\n",
    "            y_true.extend(labels_numpy.tolist())\n",
    "            \n",
    "            batch_loss += loss.item()\n",
    "            \n",
    "            \n",
    "            #accuracy+= batch_acc\n",
    "\n",
    "              \n",
    "          epoch_loss = batch_loss / (len(dataloaders[phase]))\n",
    "          #epoch_acc = accuracy / (len(dataloaders[phase]))\n",
    "\n",
    "          print(phase + \":\")\n",
    "          pre = precision_score(y_true, y_pred, average='micro')\n",
    "          recall = recall_score(y_true, y_pred, average='micro')\n",
    "          f1 = f1_score(y_true, y_pred, average='micro')\n",
    "          \n",
    "\n",
    "          print(\"Micro F1: {:.8f}, Precision: {:.8f}, Recall : {:.8f}, Loss: {:.8f}.\".format(f1, pre, recall, epoch_loss))\n",
    "          print()\n",
    "          \n",
    "            \n",
    "          if phase == 'Val':\n",
    "                \n",
    "                if f1 > best_valid_f1:\n",
    "                    best_valid_f1 = f1\n",
    "                    \n",
    "                    torch.save(model.state_dict(), PATH)\n",
    "                    print('Model Saved!')\n",
    "                    \n",
    "                scheduler.step()\n",
    "                    \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RelationClassification(electra, hidden_size, vocab_size, embed_dim, num_class)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [00:10<00:00, 59.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inference:\n",
      "\n",
      "\n",
      "F1: 0.88892952, Precision: 0.95689825, Recall : 0.82997610, Loss: 0.05899484.\n"
     ]
    }
   ],
   "source": [
    "# Test on Test loader\n",
    "\n",
    "batch_loss = 0.0   #epoch loss\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# set the model to evaluation mode            \n",
    "model.eval()\n",
    "        \n",
    "with tqdm(test_loader, unit=\"batch\") as tepoch:\n",
    "  for batch in tepoch:\n",
    "    labels = batch[\"label\"].to(device)\n",
    "    text = batch[\"token\"].to(device)\n",
    "    mask = batch['mask'].to(device)\n",
    "\n",
    "    labels = labels.to(torch.float32)\n",
    "    \n",
    "    text = text.squeeze()\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "    \n",
    "      output = model(text, mask)\n",
    "    \n",
    "      loss = criterion(output, labels)\n",
    "    \n",
    "    labels_numpy = labels.detach().cpu().numpy()\n",
    "    hard_preds = torch.round(output).detach().cpu().numpy()\n",
    "    \n",
    "    y_pred.extend(hard_preds.tolist())\n",
    "    y_true.extend(labels_numpy.tolist())\n",
    "            \n",
    "    batch_loss += loss.item()\n",
    "\n",
    "              \n",
    "epoch_loss = batch_loss / (len(test_loader))\n",
    "\n",
    "print('')\n",
    "print(\"Inference:\")\n",
    "print(\"\")\n",
    "\n",
    "pre = precision_score(y_true, y_pred, average='micro')\n",
    "recall = recall_score(y_true, y_pred, average='micro')\n",
    "f1 = f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "print(\"F1: {:.8f}, Precision: {:.8f}, Recall : {:.8f}, Loss: {:.8f}.\".format(f1, pre, recall, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NLP HW - 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
